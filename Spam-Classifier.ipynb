{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPAM CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATASETS_DIR = 'datasets'\n",
    "MODELS_DIR = 'models'\n",
    "TAR_DIR = os.path.join(DATASETS_DIR, 'tar')\n",
    "\n",
    "SPAM_URL = 'https://spamassassin.apache.org/old/publiccorpus/20050311_spam_2.tar.bz2'\n",
    "EASY_HAM_URL = 'https://spamassassin.apache.org/old/publiccorpus/20030228_easy_ham_2.tar.bz2'\n",
    "HARD_HAM_URL = 'https://spamassassin.apache.org/old/publiccorpus/20030228_hard_ham.tar.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "def download_dataset(url):\n",
    "    \"\"\"download and unzip data from a url into the specified path\"\"\"\n",
    "    \n",
    "    # create directory if it doesn't exist\n",
    "    if not os.path.isdir(TAR_DIR):\n",
    "        os.makedirs(TAR_DIR)\n",
    "    \n",
    "    filename = url.rsplit('/', 1)[-1]\n",
    "    tarpath = os.path.join(TAR_DIR, filename)\n",
    "    \n",
    "    # download the tar file if it doesn't exist\n",
    "    try:\n",
    "        tarfile.open(tarpath)\n",
    "    except:\n",
    "        urlretrieve(url, tarpath)\n",
    "    \n",
    "    with tarfile.open(tarpath) as tar:\n",
    "        dirname = os.path.join(DATASETS_DIR, tar.getnames()[0])\n",
    "        if os.path.isdir(dirname):\n",
    "            shutil.rmtree(dirname)\n",
    "        tar.extractall(path=DATASETS_DIR)\n",
    "        \n",
    "        cmds_path = os.path.join(dirname, 'cmds')\n",
    "        if os.path.isfile(cmds_path):\n",
    "            os.remove(cmds_path)\n",
    "    \n",
    "    return dirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_dir = download_dataset(SPAM_URL)\n",
    "easy_ham_dir = download_dataset(EASY_HAM_URL)\n",
    "hard_ham_dir = download_dataset(HARD_HAM_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_ham_filenames = [name for name in sorted(os.listdir(easy_ham_dir)) if len(name) > 20]\n",
    "hard_ham_filenames = [name for name in sorted(os.listdir(hard_ham_dir)) if len(name) > 20]\n",
    "spam_filenames = [name for name in sorted(os.listdir(spam_dir)) if len(name) > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(easy_ham_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hard_ham_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1396"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spam_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datasets/spam_2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import email.policy\n",
    "\n",
    "def load_email(is_spam, filename, spam_path='datasets'):\n",
    "    directory = \"spam_2\" if is_spam else \"easy_ham_2\"\n",
    "    with open(os.path.join(spam_path, directory, filename), \"rb\") as f:\n",
    "        return email.parser.BytesParser(policy=email.policy.default).parse(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_ham_emails = [load_email(is_spam=False, filename=name) for name in easy_ham_filenames]\n",
    "spam_emails = [load_email(is_spam=True, filename=name) for name in spam_filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Date:        Tue, 20 Aug 2002 17:27:47 -0500\\n    From:        Chris Garrigues <cwg-exmh@DeepEddy.Com>\\n    Message-ID:  <1029882468.3116.TMDA@deepeddy.vircio.com>\\n\\n\\n  | I\\'m hoping that all people with no additional sequences will notice are\\n  | purely cosmetic changes.\\n\\nWell, first, when exmh (the latest one with your changes) starts, I get...\\n\\ncan\\'t read \"flist(totalcount,unseen)\": no such element in array\\n    while executing\\n\"if {$flist(totalcount,$mhProfile(unseen-sequence)) > 0} {\\n\\tFlagInner spool iconspool labelup\\n    } else {\\n\\tFlagInner down icondown labeldown\\n    }\"\\n    (procedure \"Flag_MsgSeen\" line 3)\\n    invoked from within\\n\"Flag_MsgSeen\"\\n    (procedure \"MsgSeen\" line 8)\\n    invoked from within\\n\"MsgSeen $msgid\"\\n    (procedure \"MsgShow\" line 12)\\n    invoked from within\\n\"MsgShow $msgid\"\\n    (procedure \"MsgChange\" line 17)\\n    invoked from within\\n\"MsgChange 4862 show\"\\n    invoked from within\\n\"time [list MsgChange $msgid $show\"\\n    (procedure \"Msg_Change\" line 3)\\n    invoked from within\\n\"Msg_Change $msg(id) $show\"\\n    (procedure \"Msg_Show\" line 7)\\n    invoked from within\\n\"Msg_Show cur\"\\n    (\"eval\" body line 1)\\n    invoked from within\\n\"eval $msgShowProc\"\\n    (procedure \"FolderChange\" line 55)\\n    invoked from within\\n\"FolderChange inbox {Msg_Show cur}\"\\n    invoked from within\\n\"time [list  FolderChange $folder $msgShowProc\"\\n    (procedure \"Folder_Change\" line 3)\\n    invoked from within\\n\"Folder_Change $exmh(folder)\"\\n    (procedure \"Exmh\" line 101)\\n    invoked from within\\n\"Exmh\"\\n    (\"after\" script)\\n\\nwhich is probably related to my not having an \"unseen\" sequence anywhere\\n(certainly not in inbox) - I read all of my outstanding mail before I\\ntried this new exmh ...\\n\\nSecond, I\\'ve been used to having a key binding which was to Msg_MarkUnseen\\nwhich doesn\\'t seem to exist any more, and I\\'m not sure what I should replace\\nthat with.   There\\'s obviously a way as the \"Sequences\" menu does this.\\nThe \"Mark Unseen\" menu entry in the message \"More\" menu is still wanting\\nthat function as well...\\n\\n  | For those who have other sequences defined, the window will widen to\\n  | display the other sequences.\\n\\nAny chance of having that lengthen instead?   I like all my exmh stuff\\nin nice columns (fits the display better).   That is, I use the detached\\nfolder list, one column.   The main exmh window takes up full screen,\\ntop to bottom, but less than half the width, etc...\\n\\nI have space for more sequences, in the \"unseen\" window, as long as they\\nremain once nice narrow window (best would be if the sequences could be\\nordered by some preference, then ones which didn\\'t fit would just fall\\noff the bottom, and not be shown).\\n\\nI\\'d also prefer it if that window had no unusual background colouring,\\njust one constant colour - I have been running the unseen window with\\nbackground black, on a root window that is all black, with no borders or\\nother decorations, but made \"sticky\" - the appearance is just like the\\nfolders with unseen messages (and their counts) are written into the\\nroot window (because it is sticky, this small display follows me around\\nand do I can see when new mail needs processing).\\n\\nI also find that I tend to have a bunch of sequences that only ever occur\\nin one folder (some I had forgotten I ever created).  So in addition to\\nthe \"sequences to always show\" and \"sequences to never show\", a\\npreference to only show sequences that occur in more than one folder\\nwould be useful, and then have the sequences that occor only in the\\nfolder I\\'m visiting appear in the list when that folder is current.\\nThis is just to keep the list size somewhat manageable while remaining\\nproductive (I quite often use a sequence to remember a particular message\\nin a folder - the name is used only there, and only for one message,\\nit gives me a handle on the message which remains as the folder is\\npacked, sorted, etc).\\n\\nI haven\\'t updated my exmh for some time now, so I\\'m not sure if this\\nnext one is new, or just new since 2.5, but the Sequences menu (on the\\nbar with New Flist Search ...) only contains \"unseen\" and \"urgent\".\\nIt would be useful if it contained all of the sequences that the folder\\nhappens to have defined.   A \"New sequence\" entry would also be useful\\n(to mark the message with a sequence name that didn\\'t previously exist,\\nwhich can be done now using \"Search\" and the pick interface, but is\\nclumsy that way)\\n\\nActually, you once could, now when I try this, entering a sequence name\\nin the pick box, and a single message number, or a range N-N in the\\nlist of messages, and no pick attributes at all, I now get ...\\n\\nsyntax error in expression \"int(1+1+(1 hit-1)*(3868-1-2)/(4878-1))\"\\n    while executing\\n\"expr int($minlineno+1+($msgid-$minmsgid)*($maxlineno-$minlineno-2)/($maxmsgid-$minmsgid))\"\\n    (procedure \"Ftoc_FindMsg\" line 46)\\n    invoked from within\\n\"Ftoc_FindMsg $msg\"\\n    (procedure \"Ftoc_FindMsgs\" line 5)\\n    invoked from within\\n\"Ftoc_FindMsgs $msgids\"\\n    (procedure \"Ftoc_PickMsgs\" line 5)\\n    invoked from within\\n\"Ftoc_PickMsgs $pick(ids) $pick(addtosel)\"\\n    (procedure \"PickInner\" line 13)\\n    invoked from within\\n\"PickInner {exec pick +inbox -list} {4852 -sequence mercury}\"\\n    (\"uplevel\" body line 1)\\n    invoked from within\\n\"uplevel #0 $cmd\"\\n    (procedure \"busyCursorInner\" line 8)\\n    invoked from within\\n\"busyCursorInner $cmd $widgets\"\\n    (procedure \"busyCursorHack\" line 32)\\n    invoked from within\\n\"busyCursorHack $args\"\\n    (\"cursor\" arm line 1)\\n    invoked from within\\n\"switch $busy(style) {\\n\\ticon\\t\\t{busyIcon $args}\\n\\tcursorAll\\t{busyCursor $args}\\n\\tcursor\\t\\t{busyCursorHack $args}\\n\\tdefault\\t\\t{eval $args}\\n    }\"\\n    (procedure \"busy\" line 3)\\n    invoked from within\\n\"busy PickInner $cmd $msgs\"\\n    (procedure \"Pick_It\" line 51)\\n    invoked from within\\n\"Pick_It\"\\n    invoked from within\\n\".pick.but.pick invoke\"\\n    (\"uplevel\" body line 1)\\n    invoked from within\\n\"uplevel #0 [list $w invoke]\"\\n    (procedure \"tkButtonUp\" line 7)\\n    invoked from within\\n\"tkButtonUp .pick.but.pick\\n\"\\n    (command bound to event)\\n\\nIt has been ages since I did this last though.   I tried adding a Subject\\nto pick on (easy as I know what\\'s in the message...) which made no difference.\\nLooks as if something is now saying \"1 hit\" when before it didn\\'t, or\\nsimilar.\\n\\n  | I\\'ve also changed the ftoc colorization as discussed briefly on the list a \\n  | week or so ago.\\n\\nAny chance of making the current message a little brighter background?\\nJust to make it stand out a fraction more than it does (maybe this is\\nmore apparent to me than many, as I use very small fonts everywhere,\\nthe background of the ftoc line isn\\'t very wide).\\n\\nHope this helps.\\n\\nkre\\n\\n\\n\\n_______________________________________________\\nExmh-workers mailing list\\nExmh-workers@redhat.com\\nhttps://listman.redhat.com/mailman/listinfo/exmh-workers'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easy_ham_emails[0].get_content().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes we do purchase uncollected Judicial Judgements!!!            st10                           .           \\n\\nIf you, your company or an acquaintance have an uncollected Judicial Judgement then please call us and find out how we can help you receive the money that the court states you are rightfully due.\\n\\nWe have strong interest in acquiring uncollected Judicial Judgements in your City and Area.\\n\\nJ T C is the largest firm in the world specializing in the purchase and collection of Judicial Judgements.\\n\\nCurrently we are processing over 455 million dollars worth of judgements in the United States alone. We have associate offices in virtually every city in the US and in most foreign countries.\\n\\nYou have nothing to lose and everything to gain by calling. There is absolutely no cost to you.\\n\\nWe can be reached Toll free at 1-888-557-5744. in the US or if you are in Canada call 1-310-842-3521. You can call 24 hours per day.\\n\\nThank you for your time.\\n\\n\\n\\n\\n\\n\\n\\n++++++++++++++++++++++++++++++++++++++++++++++++++++\\nThis ad is produced and sent out by: Add Systems,  NY, NY 1 1 2 2 2. To be  r e m o v e d from our mailing list please email us at boogins@hiphopmaster.com  with r e m o v e in the subject.\\n++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\\n\\n***********************************\\n9385'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_emails[10].get_content().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring email structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_structure(email):\n",
    "    if isinstance(email, str):\n",
    "        return email\n",
    "    payload = email.get_payload()\n",
    "    if isinstance(payload, list):\n",
    "        return \"multipart({})\".format(\", \".join([\n",
    "            get_email_structure(sub_email)\n",
    "            for sub_email in payload\n",
    "        ]))\n",
    "    else:\n",
    "        return email.get_content_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def structures_counter(emails):\n",
    "    structures = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 1\n",
    "    return structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 1343),\n",
       " ('multipart(text/plain, application/pgp-signature)', 35),\n",
       " ('multipart(text/plain, text/html)', 12),\n",
       " ('text/html', 2),\n",
       " ('multipart(text/plain, application/x-patch)', 1),\n",
       " ('multipart(multipart(text/plain, multipart(text/plain), text/plain), application/pgp-signature)',\n",
       "  1),\n",
       " ('multipart(text/plain, multipart(text/plain))', 1),\n",
       " ('multipart(multipart(text/plain, text/html), image/jpeg, image/gif, image/gif, image/gif, image/gif)',\n",
       "  1),\n",
       " ('multipart(text/plain, application/ms-tnef)', 1),\n",
       " ('multipart(text/plain, text/plain, text/plain)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)',\n",
       "  1),\n",
       " ('multipart(text/plain, application/ms-tnef, text/plain)', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_counter(easy_ham_emails).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 597),\n",
       " ('text/html', 589),\n",
       " ('multipart(text/plain, text/html)', 114),\n",
       " ('multipart(text/html)', 29),\n",
       " ('multipart(text/plain)', 25),\n",
       " ('multipart(multipart(text/html))', 18),\n",
       " ('multipart(multipart(text/plain, text/html))', 5),\n",
       " ('multipart(text/plain, application/octet-stream, text/plain)', 3),\n",
       " ('multipart(text/html, text/plain)', 2),\n",
       " ('multipart(text/html, image/jpeg)', 2),\n",
       " ('multipart(multipart(text/plain), application/octet-stream)', 2),\n",
       " ('multipart(text/plain, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, multipart(text/plain))', 1),\n",
       " ('multipart(multipart(text/plain, text/html), image/jpeg, image/jpeg, image/jpeg, image/jpeg, image/jpeg)',\n",
       "  1),\n",
       " ('multipart(multipart(text/plain, text/html), image/jpeg, image/jpeg, image/jpeg, image/jpeg, image/gif)',\n",
       "  1),\n",
       " ('text/plain charset=us-ascii', 1),\n",
       " ('multipart(multipart(text/html), image/gif)', 1),\n",
       " ('multipart(multipart(text/plain, text/html), application/octet-stream, application/octet-stream, application/octet-stream, application/octet-stream)',\n",
       "  1),\n",
       " ('multipart(multipart(text/plain, text/html), image/gif, image/jpeg)', 1),\n",
       " ('multipart/alternative', 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_counter(spam_emails).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return-Path : <ilug-admin@linux.ie>\n",
      "Delivered-To : yyyy@localhost.netnoteinc.com\n",
      "Received : from localhost (localhost [127.0.0.1])\tby phobos.labs.netnoteinc.com (Postfix) with ESMTP id 9E1F5441DD\tfor <jm@localhost>; Tue,  6 Aug 2002 06:48:09 -0400 (EDT)\n",
      "Received : from phobos [127.0.0.1]\tby localhost with IMAP (fetchmail-5.9.0)\tfor jm@localhost (single-drop); Tue, 06 Aug 2002 11:48:09 +0100 (IST)\n",
      "Received : from lugh.tuatha.org (root@lugh.tuatha.org [194.125.145.45]) by    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g72LqWv13294 for    <jm-ilug@jmason.org>; Fri, 2 Aug 2002 22:52:32 +0100\n",
      "Received : from lugh (root@localhost [127.0.0.1]) by lugh.tuatha.org    (8.9.3/8.9.3) with ESMTP id WAA31224; Fri, 2 Aug 2002 22:50:17 +0100\n",
      "Received : from bettyjagessar.com (w142.z064000057.nyc-ny.dsl.cnc.net    [64.0.57.142]) by lugh.tuatha.org (8.9.3/8.9.3) with ESMTP id WAA31201 for    <ilug@linux.ie>; Fri, 2 Aug 2002 22:50:11 +0100\n",
      "X-Authentication-Warning : lugh.tuatha.org: Host w142.z064000057.nyc-ny.dsl.cnc.net    [64.0.57.142] claimed to be bettyjagessar.com\n",
      "Received : from 64.0.57.142 [202.63.165.34] by bettyjagessar.com    (SMTPD32-7.06 EVAL) id A42A7FC01F2; Fri, 02 Aug 2002 02:18:18 -0400\n",
      "Message-Id : <1028311679.886@0.57.142>\n",
      "Date : Fri, 02 Aug 2002 23:37:59 +0530\n",
      "To : ilug@linux.ie\n",
      "From : Start Now <startnow2002@hotmail.com>\n",
      "MIME-Version : 1.0\n",
      "Content-Type : text/plain; charset=\"US-ASCII\"; format=\"flowed\"\n",
      "Subject : [ILUG] STOP THE MLM INSANITY\n",
      "Sender : ilug-admin@linux.ie\n",
      "Errors-To : ilug-admin@linux.ie\n",
      "X-Mailman-Version : 1.1\n",
      "Precedence : bulk\n",
      "List-Id : Irish Linux Users' Group <ilug.linux.ie>\n",
      "X-Beenthere : ilug@linux.ie\n"
     ]
    }
   ],
   "source": [
    "for header, value in spam_emails[0].items():\n",
    "    print(header,\":\",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ILUG] STOP THE MLM INSANITY'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_emails[0][\"Subject\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(easy_ham_emails + spam_emails)\n",
    "y = np.array([0] * len(easy_ham_emails) + [1] * len(spam_emails))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling HTML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from html import unescape\n",
    "\n",
    "def html_to_plain_text(html):\n",
    "    text = re.sub('<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<a\\s.*?>', ' HYPERLINK ', text, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<.*?>', '', text, flags=re.M | re.S)\n",
    "    text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S)\n",
    "    return unescape(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HR>\n",
      "<html>\n",
      "<div bgcolor=\"#FFFFCC\">\n",
      "\n",
      "  <p align=\"center\"><a\n",
      "href=\"http://www.fabulousmail.com\"><img border=\"0\"\n",
      "src=\"http://www.fabulousmail.com/Toners2goLogo.jpg\"\n",
      "width=\"349\" height=\"96\"></a></p>\n",
      "<p align=\"center\"><font size=\"6\" face=\"Arial MT\n",
      "Black\"><i>Tremendous Savings</i>\n",
      "on Toners,&nbsp;</font></p>\n",
      "<p align=\"center\"><font size=\"6\" face=\"Arial MT\n",
      "Black\">\n",
      "Inkjets, FAX, and Thermal Replenishables!!</font></p>\n",
      "<p><a href=\"http://www.fabulousmail.com\">Toners 2 Go\n",
      "</a>is your secret\n",
      "weapon to lowering your cost for <a\n",
      "href=\"http://www.fabulousmail.com\">High Quality,\n",
      "Low-Cost</a> printer\n",
      "supplies!&nbsp; We have been in the printer\n",
      "replenishables business since 1992,\n",
      "and pride ourselves on rapid response and outstanding\n",
      "customer service.&nbsp;\n",
      "What we sell are 100% compatible replacements for\n",
      "Epson, Canon, Hewlett Packard,\n",
      "Xerox, Okidata, Brother, and Lexmark; products that\n",
      "meet and often exceed\n",
      "original manufacturer's specifications.</p>\n",
      "<p><i><font size=\"4\">Check out these\n",
      "prices!</font ...\n"
     ]
    }
   ],
   "source": [
    "html_spam_emails = [email for email in X_train[y_train==1]\n",
    "                    if get_email_structure(email) == \"text/html\"]\n",
    "sample_html_spam = html_spam_emails[7]\n",
    "print(sample_html_spam.get_content().strip()[:1000], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   HYPERLINK\n",
      "Tremendous Savings\n",
      "on Toners, \n",
      "Inkjets, FAX, and Thermal Replenishables!!\n",
      " HYPERLINK Toners 2 Go\n",
      "is your secret\n",
      "weapon to lowering your cost for  HYPERLINK High Quality,\n",
      "Low-Cost printer\n",
      "supplies!  We have been in the printer\n",
      "replenishables business since 1992,\n",
      "and pride ourselves on rapid response and outstanding\n",
      "customer service. \n",
      "What we sell are 100% compatible replacements for\n",
      "Epson, Canon, Hewlett Packard,\n",
      "Xerox, Okidata, Brother, and Lexmark; products that\n",
      "meet and often exceed\n",
      "original manufacturer's specifications.\n",
      "Check out these\n",
      "prices!\n",
      "        Epson Stylus\n",
      "Color inkjet cartridge\n",
      "(SO20108):     Epson's Price:\n",
      "$27.99    \n",
      "Toners2Go price: $9.95!\n",
      "         HP\n",
      "LaserJet 4 Toner Cartridge\n",
      "(92298A):           \n",
      "HP's\n",
      "Price:\n",
      "$88.99           \n",
      "Toners2Go\n",
      "  price: $41.75!\n",
      " \n",
      "Come visit us on the web to check out our hundreds\n",
      "of similar bargains at  HYPERLINK Toners\n",
      "2 Go!\n",
      "  request to be removed by clicking  HYPERLINK HERE\n",
      "derekw\n",
      "http://xent.com/mailman/listinfo/fork\n",
      " ...\n"
     ]
    }
   ],
   "source": [
    "print(html_to_plain_text(sample_html_spam.get_content())[:1000], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_to_text(email):\n",
    "    html = None\n",
    "    for part in email.walk():\n",
    "        ctype = part.get_content_type()\n",
    "        if not ctype in (\"text/plain\", \"text/html\"):\n",
    "            continue\n",
    "        try:\n",
    "            content = part.get_content()\n",
    "        except: # in case of encoding issues\n",
    "            content = str(part.get_payload())\n",
    "        if ctype == \"text/plain\":\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return html_to_plain_text(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   HYPERLINK\n",
      "Tremendous Savings\n",
      "on Toners, \n",
      "Inkjets, FAX, and Thermal Replenishables!!\n",
      " HYPERLINK T ...\n"
     ]
    }
   ],
   "source": [
    "print(email_to_text(sample_html_spam)[:100], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install NLTK (http://www.nltk.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 6.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click (from nltk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl (82kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 18.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib (from nltk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/a6/d1a816b89aa1e9e96bcb298eb1ee1854f21662ebc6d55ffa3d7b3b50122b/joblib-0.15.1-py3-none-any.whl (298kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 8.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex (from nltk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/7c/0d46b10a87b3087e8e303fac923beb19ec839d7c5ea34971a12fafb22b52/regex-2020.5.14-cp36-cp36m-manylinux2010_x86_64.whl (675kB)\n",
      "\u001b[K     |████████████████████████████████| 686kB 25.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm (from nltk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/40/058b12e8ba10e35f89c9b1fdfc2d4c7f8c05947df2d5eb3c7b258019fda0/tqdm-4.46.0-py2.py3-none-any.whl (63kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 5.5MB/s  eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyterlab/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "Successfully built nltk\n",
      "Installing collected packages: click, joblib, regex, tqdm, nltk\n",
      "Successfully installed click-7.1.2 joblib-0.15.1 nltk-3.5 regex-2020.5.14 tqdm-4.46.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computations => comput\n",
      "Computation => comput\n",
      "Computing => comput\n",
      "Computed => comput\n",
      "Compute => comput\n",
      "Compulsive => compuls\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import nltk\n",
    "\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    for word in (\"Computations\", \"Computation\", \"Computing\", \"Computed\", \"Compute\", \"Compulsive\"):\n",
    "        print(word, \"=>\", stemmer.stem(word))\n",
    "except ImportError:\n",
    "    print(\"Error: stemming requires the NLTK module.\")\n",
    "    stemmer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: replacing URLs requires the urlextract module.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import urlextract # may require an Internet connection to download root domain names\n",
    "    \n",
    "    url_extractor = urlextract.URLExtract()\n",
    "    print(url_extractor.find_urls(\"Will it detect github.com and https://youtu.be/7Pq-S557XQU?t=3m32s\"))\n",
    "except ImportError:\n",
    "    print(\"Error: replacing URLs requires the urlextract module.\")\n",
    "    url_extractor = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert emails into word counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip_headers=True, lower_case=True, remove_punctuation=True,\n",
    "                 replace_urls=True, replace_numbers=True, stemming=True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.lower_case = lower_case\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_urls = replace_urls\n",
    "        self.replace_numbers = replace_numbers\n",
    "        self.stemming = stemming\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for email in X:\n",
    "            text = email_to_text(email) or \"\"\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.replace_urls and url_extractor is not None:\n",
    "                urls = list(set(url_extractor.find_urls(text)))\n",
    "                urls.sort(key=lambda url: len(url), reverse=True)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \" URL \")\n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', 'NUMBER', text)\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
    "            word_counts = Counter(text.split())\n",
    "            if self.stemming and stemmer is not None:\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word, count in word_counts.items():\n",
    "                    stemmed_word = stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "            X_transformed.append(word_counts)\n",
    "        return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Counter({'number': 8, 'to': 5, 'mail': 4, 'thi': 3, 'http': 3, 'www': 3, 'year': 2, 'annuiti': 2, 'or': 2, 'e': 2, 'insur': 2, 'com': 2, 'not': 2, 'profession': 2, 'insurancemail': 2, 'net': 2, 'legal': 2, 'holi': 1, 'cow': 1, 'guarante': 1, 'rate': 1, 'commiss': 1, 'surrend': 1, 'limit': 1, 'time': 1, 'onli': 1, 'call': 1, 'mailto': 1, 'safe': 1, 'us': 1, 'today': 1, 'pleas': 1, 'fill': 1, 'out': 1, 'the': 1, 'form': 1, 'below': 1, 'for': 1, 'more': 1, 'inform': 1, 'name': 1, 'phone': 1, 'citi': 1, 'state': 1, 'we': 1, 'don': 1, 't': 1, 'want': 1, 'anyon': 1, 'receiv': 1, 'our': 1, 'who': 1, 'doe': 1, 'wish': 1, 'is': 1, 'commun': 1, 'sent': 1, 'be': 1, 'remov': 1, 'from': 1, 'list': 1, 'do': 1, 'repli': 1, 'messag': 1, 'instead': 1, 'go': 1, 'here': 1, 'notic': 1, 'insiq': 1, 'htm': 1}),\n",
       "       Counter({'to': 17, 'you': 16, 'a': 9, 'number': 9, 'we': 8, 'for': 7, 'be': 7, 'your': 7, 'thi': 6, 'stori': 5, 'are': 5, 'if': 5, 'us': 5, 'look': 4, 'tell': 4, 'i': 3, 'am': 3, 'tv': 3, 'one': 3, 'the': 3, 'and': 3, 'on': 3, 'abl': 3, 's': 3, 'find': 3, 'love': 3, 'repli': 3, 'reach': 3, 'of': 2, 'work': 2, 'special': 2, 'is': 2, 'not': 2, 'pleas': 2, 'here': 2, 'interest': 2, 'singl': 2, 'nation': 2, 'have': 2, 'will': 2, 'need': 2, 'email': 2, 'want': 2, 'by': 2, 'phone': 2, 'produc': 1, 'three': 1, 'major': 1, 'network': 1, 'new': 1, 'primetim': 1, 're': 1, 'thought': 1, 'might': 1, 'assist': 1, 'sale': 1, 'pitch': 1, 'anyth': 1, 'realli': 1, 'great': 1, 'read': 1, 'type': 1, 'seek': 1, 'in': 1, 'long': 1, 'lost': 1, 'from': 1, 'past': 1, 'first': 1, 'that': 1, 'got': 1, 'away': 1, 'may': 1, 'make': 1, 'dream': 1, 'come': 1, 'true': 1, 'send': 1, 'friend': 1, 'consid': 1, 'rare': 1, 'opportun': 1, 'must': 1, 'avail': 1, 'sincer': 1, 'former': 1, 'share': 1, 'travel': 1, 'lo': 1, 'angel': 1, 'pay': 1, 'everyth': 1, 'then': 1, 'what': 1, 'do': 1, 'next': 1, 'who': 1, 'whi': 1, 'him': 1, 'her': 1, 'let': 1, 'feel': 1, 'out': 1, 'where': 1, 'they': 1, 'were': 1, 'last': 1, 'time': 1, 'saw': 1, 'them': 1, 'specif': 1, 'how': 1, 'home': 1, 'cell': 1, 'cannot': 1, 'move': 1, 'without': 1, 'onli': 1, 'so': 1, 'it': 1, 'immedi': 1, 'forward': 1, 'get': 1, 'soon': 1, 'good': 1, 'luck': 1, 'p': 1, 'rememb': 1, 'give': 1, 'way': 1, 'today': 1}),\n",
       "       Counter({'the': 15, 'to': 9, 'a': 8, 'you': 7, 'it': 6, 'of': 6, 'with': 5, 'and': 5, 'problem': 5, 'g': 4, 'out': 4, 'that': 4, 'number': 4, 'in': 4, 're': 4, 's': 4, 'not': 3, 'just': 3, 'surpris': 3, 'i': 3, 'there': 3, 'can': 3, 'com': 3, 'no': 2, 'collis': 2, 'at': 2, 'bodi': 2, 'over': 2, 'mani': 2, 'time': 2, 'even': 2, 'befor': 2, 'is': 2, 'still': 2, 'if': 2, 'are': 2, 'go': 2, 'nudg': 2, 'rock': 2, 'thi': 2, 'forc': 2, 'up': 2, 'when': 2, 'they': 2, 'onli': 2, 'get': 2, 'do': 2, 'system': 2, 'teledyn': 2, 'http': 2, 'gordon': 1, 'mohr': 1, 'gojomo': 1, 'usa': 1, 'net': 1, 'write': 1, 'voila': 1, 'least': 1, 'initi': 1, 'threat': 1, 'need': 1, 'travel': 1, 'anywher': 1, 'near': 1, 'meteor': 1, 'either': 1, 'moon': 1, 'yeah': 1, 'right': 1, 'consid': 1, 'genesi': 1, 'project': 1, 'won': 1, 'an': 1, 'award': 1, 'for': 1, 'figur': 1, 'n': 1, 'yield': 1, 'some': 1, 'interest': 1, 'synerget': 1, 'suffic': 1, 'say': 1, 'issu': 1, 'ha': 1, 'been': 1, 'hash': 1, 'sci': 1, 'astro': 1, 'sinc': 1, 'long': 1, 'hollywood': 1, 'pose': 1, 'veri': 1, 'best': 1, 'advic': 1, 'duck': 1, 'cover': 1, 'anyth': 1, 'though': 1, 'd': 1, 'one': 1, 'size': 1, 'small': 1, 'town': 1, 'as': 1, 'less': 1, 'like': 1, 'defin': 1, 'global': 1, 'agricultur': 1, 'way': 1, 'cours': 1, 'gonna': 1, 'have': 1, 'distribut': 1, 'larg': 1, 'enough': 1, 'surfac': 1, 'area': 1, 'translat': 1, 'into': 1, 'resilli': 1, 'compress': 1, 'wave': 1, 'instead': 1, 'knifeblad': 1, 'diamond': 1, 'faultlin': 1, 'split': 1, 'also': 1, 'game': 1, 'billiard': 1, 'but': 1, 'dimension': 1, 'space': 1, 'spin': 1, 'temp': 1, 'mayb': 1, 'electromag': 1, 'too': 1, 'ani': 1, 'heavi': 1, 'metal': 1, 'often': 1, 'complet': 1, 'relativist': 1, 'effect': 1, 'everyth': 1, 'hand': 1, 'all': 1, 'those': 1, 'experi': 1, 'subject': 1, 'blackbox': 1, 'alien': 1, 'geolog': 1, 'sustain': 1, 'excess': 1, 'megaton': 1, 'own': 1, 'momentum': 1, 'm': 1, 'trust': 1, 'us': 1, 'armi': 1, 't': 1, 'find': 1, 'more': 1, 'than': 1, 'few': 1, 'hundr': 1, 'al': 1, 'queda': 1, 'desert': 1, 'oh': 1, 'anoth': 1, 'we': 1, 'better': 1, 'spot': 1, 'them': 1, 'tell': 1, 'ya': 1, 'what': 1, 'cowboy': 1, 'readi': 1, 'balli': 1, 'hootin': 1, 'blow': 1, 'er': 1, 'real': 1, 'good': 1, 'let': 1, 'me': 1, 'know': 1, 'eh': 1, 'so': 1, 'move': 1, 'next': 1, 'solar': 1, 'gari': 1, 'lawrenc': 1, 'murphi': 1, 'garym': 1, 'teledynam': 1, 'commun': 1, 'inc': 1, 'busi': 1, 'innov': 1, 'through': 1, 'open': 1, 'sourc': 1, 'www': 1, 'comput': 1, 'useless': 1, 'give': 1, 'answer': 1, 'pablo': 1, 'picasso': 1, 'xent': 1, 'mailman': 1, 'listinfo': 1, 'fork': 1})],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few = X_train[:3]\n",
    "X_few_wordcounts = EmailToWordCounterTransformer().fit_transform(X_few)\n",
    "X_few_wordcounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert word counts to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocabulary_size=1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "    def fit(self, X, y=None):\n",
    "        total_count = Counter()\n",
    "        for word_count in X:\n",
    "            for word, count in word_count.items():\n",
    "                total_count[word] += min(count, 10)\n",
    "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
    "        self.most_common_ = most_common\n",
    "        self.vocabulary_ = {word: index + 1 for index, (word, count) in enumerate(most_common)}\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        for row, word_count in enumerate(X):\n",
    "            for word, count in word_count.items():\n",
    "                rows.append(row)\n",
    "                cols.append(self.vocabulary_.get(word, 0))\n",
    "                data.append(count)\n",
    "        return csr_matrix((data, (rows, cols)), shape=(len(X), self.vocabulary_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x11 sparse matrix of type '<class 'numpy.longlong'>'\n",
       "\twith 29 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size=10)\n",
    "X_few_vectors = vocab_transformer.fit_transform(X_few_wordcounts)\n",
    "X_few_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 81,   5,   8,   0,   0,   1,   3,   1,   1,   1,   0],\n",
       "       [189,  17,   9,   9,  16,   3,   6,   8,   7,   7,   2],\n",
       "       [290,   9,   4,   8,   7,  15,   2,   1,   1,   0,   6]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to': 1,\n",
       " 'number': 2,\n",
       " 'a': 3,\n",
       " 'you': 4,\n",
       " 'the': 5,\n",
       " 'thi': 6,\n",
       " 'we': 7,\n",
       " 'for': 8,\n",
       " 'be': 9,\n",
       " 'of': 10}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocess_pipeline = Pipeline([\n",
    "    (\"email_to_wordcount\", EmailToWordCounterTransformer()),\n",
    "    (\"wordcount_to_vector\", WordCounterToVectorTransformer()),\n",
    "])\n",
    "\n",
    "X_train_transformed = preprocess_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.9865951742627346, total=   0.3s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................ , score=0.985254691689008, total=   0.4s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................... , score=0.9865591397849462, total=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.986136335245563"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "score = cross_val_score(log_clf, X_train_transformed, y_train, verbose=3)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ....................... , score=0.9463806970509383, total=   2.9s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.9369973190348525, total=   3.2s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    6.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.9543010752688172, total=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    9.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9458930304515359"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf = SVC(gamma='auto')\n",
    "score = cross_val_score(svc_clf, X_train_transformed, y_train, verbose=3)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................ , score=0.985254691689008, total=   0.2s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................... , score=0.9798927613941019, total=   0.2s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.9690860215053764, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9780778248628287"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svc = LinearSVC()\n",
    "score = cross_val_score(linear_svc, X_train_transformed, y_train, verbose=3)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ........................ , score=0.935656836461126, total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................... , score=0.9436997319034852, total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................... , score=0.9489247311827957, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9427604331824689"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(max_depth=5)\n",
    "score = cross_val_score(tree_clf, X_train_transformed, y_train, verbose=3)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9637733383301142"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "score = cross_val_score(rnd_clf, X_train_transformed, y_train)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model):\n",
    "    X_test_transformed = preprocess_pipeline.transform(X_test)\n",
    "    model.fit(X_train_transformed, y_train)\n",
    "    y_pred = model.predict(X_test_transformed)\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test,y_pred)))\n",
    "    print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test,y_pred)))\n",
    "    print(\"F1: {:.2f}%\".format(100 * f1_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[269   4]\n",
      " [  3 284]]\n",
      "Precision: 98.61%\n",
      "Recall: 98.95%\n",
      "F1: 98.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "prediction(log_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[260  13]\n",
      " [ 13 274]]\n",
      "Precision: 95.47%\n",
      "Recall: 95.47%\n",
      "F1: 95.47%\n"
     ]
    }
   ],
   "source": [
    "prediction(svc_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[269   4]\n",
      " [  9 278]]\n",
      "Precision: 98.58%\n",
      "Recall: 96.86%\n",
      "F1: 97.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "prediction(linear_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[257  16]\n",
      " [ 12 275]]\n",
      "Precision: 94.50%\n",
      "Recall: 95.82%\n",
      "F1: 95.16%\n"
     ]
    }
   ],
   "source": [
    "prediction(tree_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[264   9]\n",
      " [  5 282]]\n",
      "Precision: 96.91%\n",
      "Recall: 98.26%\n",
      "F1: 97.58%\n"
     ]
    }
   ],
   "source": [
    "prediction(rnd_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
